import streamlit as st
import os
import json
from pathlib import Path

# ì„¤ì • íŒŒì¼ ê²½ë¡œ
CONFIG_PATH = Path("config.json")

# ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
DEFAULT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ìœ ìš©í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
ë¶€ì ì ˆí•˜ê±°ë‚˜ ìœ í•´í•œ ë‚´ìš©ì€ ë‹µë³€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."""

# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
MODELS = {
    "Gemini 1.5 Flash": "gemini-1.5-flash",
    "Gemini 1.5 Pro": "gemini-1.5-pro"
}

def load_config():
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    if CONFIG_PATH.exists():
        with open(CONFIG_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {
        "api_key": "",
        "system_prompt": DEFAULT_SYSTEM_PROMPT,
        "selected_model": "gemini-1.5-flash"
    }

def save_config(api_key, system_prompt, selected_model):
    """ì„¤ì • íŒŒì¼ ì €ì¥"""
    config = {
        "api_key": api_key,
        "system_prompt": system_prompt,
        "selected_model": selected_model
    }
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Gemini ì±—ë´‡", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "page" not in st.session_state:
    st.session_state.page = "settings"

# ë„¤ë¹„ê²Œì´ì…˜
col1, col2 = st.columns([1, 5])
with col1:
    if st.button("âš™ï¸ ì„¤ì •"):
        st.session_state.page = "settings"
with col2:
    if st.button("ğŸ’¬ ì±„íŒ…"):
        st.session_state.page = "chat"

# ì„¤ì • í˜ì´ì§€
if st.session_state.page == "settings":
    st.title("ì„¤ì •")
    
    # í˜„ì¬ ì„¤ì • ë¡œë“œ
    config = load_config()
    
    # API í‚¤ ì…ë ¥
    api_key = st.text_input(
        "Gemini API í‚¤",
        value=config["api_key"],
        type="password",
        help="Google AI Studioì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    )
    
    # ëª¨ë¸ ì„ íƒ
    selected_model = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸",
        options=list(MODELS.keys()),
        index=list(MODELS.values()).index(config["selected_model"]),
        help="Flash: ë¹ ë¥¸ ì‘ë‹µ, Pro: ê³ ì„±ëŠ¥"
    )
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì…ë ¥
    system_prompt = st.text_area(
        "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
        value=config["system_prompt"],
        height=200,
        help="AIì˜ ê¸°ë³¸ í–‰ë™ê³¼ ì‘ë‹µ ë°©ì‹ì„ ì„¤ì •í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤"
    )
    
    # ì €ì¥ ë²„íŠ¼
    if st.button("ì„¤ì • ì €ì¥"):
        save_config(api_key, system_prompt, MODELS[selected_model])
        st.success("ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
# ì±„íŒ… í˜ì´ì§€
elif st.session_state.page == "chat":
    import google.generativeai as genai
    from PIL import Image
    
    # ì„¤ì • ë¡œë“œ
    config = load_config()
    
    if not config["api_key"]:
        st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • í˜ì´ì§€ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # Gemini ì„¤ì •
        genai.configure(api_key=config["api_key"])
        model = genai.GenerativeModel(config["selected_model"])
        
        st.title("Gemini ì±—ë´‡")
        
        # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ í‘œì‹œ
        st.info(f"í˜„ì¬ ëª¨ë¸: {[k for k, v in MODELS.items() if v == config['selected_model']][0]}")
        
        # ì‚¬ì´ë“œë°”ì— íŒŒì¼ ì—…ë¡œë“œ
        with st.sidebar:
            st.header("íŒŒì¼ ì—…ë¡œë“œ")
            uploaded_file = st.file_uploader(
                "ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
                type=['png', 'jpg', 'jpeg']
            )
            
            if uploaded_file:
                image = Image.open(uploaded_file)
                st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€")
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
        
        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.write(prompt)
            
            try:
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í¬í•¨í•˜ì—¬ ë©”ì‹œì§€ ìƒì„±
                messages = [{
                    "parts": [config["system_prompt"]],
                    "role": "user"
                }]
                
                # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
                for msg in st.session_state.messages:
                    messages.append({
                        "parts": [msg["content"]],
                        "role": "model" if msg["role"] == "assistant" else "user"
                    })
                
                # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°
                if uploaded_file:
                    response = model.generate_content([prompt, image])
                else:
                    chat = model.start_chat(history=messages)
                    response = chat.send_message(prompt)
                
                # ì‘ë‹µ í‘œì‹œ ë° ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response.text
                })
                with st.chat_message("assistant"):
                    st.write(response.text)
                    
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.messages = []
            st.experimental_rerun()