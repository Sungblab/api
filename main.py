import streamlit as st
from anthropic import Anthropic
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
import os
import tempfile
from PyPDF2 import PdfReader
import docx

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Claude RAG ì±—ë´‡", page_icon="ğŸ¤–", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "initialized" not in st.session_state:
    st.session_state.initialized = False
    st.session_state.messages = []
    st.session_state.vectorstore = None
    st.session_state.settings_confirmed = False

def initialize_settings():
    st.title("ì´ˆê¸° ì„¤ì • âš™ï¸")
    
    # API í‚¤ ì„¤ì •
    api_key = st.text_input("Anthropic API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    default_instruction = """You are a helpful AI assistant. Please provide accurate and helpful responses based on the given context."""
    system_prompt = st.text_area("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", value=default_instruction, height=150)
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader("ì°¸ê³ í•  ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF, DOCX, TXT)", 
                                    accept_multiple_files=True,
                                    type=['pdf', 'docx', 'txt'])

    # ì„¤ì • í™•ì¸ ë²„íŠ¼
    if st.button("ì„¤ì • ì™„ë£Œ"):
        if not api_key:
            st.error("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        
        if uploaded_files:
            with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬ì¤‘ì…ë‹ˆë‹¤..."):
                texts = []
                for file in uploaded_files:
                    # íŒŒì¼ í™•ì¥ì í™•ì¸
                    file_extension = os.path.splitext(file.name)[1].lower()
                    
                    # PDF íŒŒì¼ ì²˜ë¦¬
                    if file_extension == '.pdf':
                        pdf_reader = PdfReader(file)
                        for page in pdf_reader.pages:
                            texts.append(page.extract_text())
                    
                    # DOCX íŒŒì¼ ì²˜ë¦¬
                    elif file_extension == '.docx':
                        doc = docx.Document(file)
                        for para in doc.paragraphs:
                            texts.append(para.text)
                    
                    # TXT íŒŒì¼ ì²˜ë¦¬
                    elif file_extension == '.txt':
                        texts.append(file.read().decode('utf-8'))

                # í…ìŠ¤íŠ¸ ë¶„í• 
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=1000,
                    chunk_overlap=200,
                    length_function=len
                )
                chunks = text_splitter.create_documents(texts)

                # ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„±
                embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")
                vectorstore = FAISS.from_documents(chunks, embeddings)
                st.session_state.vectorstore = vectorstore

        # ì„¸ì…˜ ìƒíƒœ ì €ì¥
        st.session_state.anthropic_api_key = api_key
        st.session_state.system_prompt = system_prompt
        st.session_state.settings_confirmed = True
        st.session_state.initialized = True
        st.success("ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()

def chat_interface():
    st.title("Claude RAG ì±—ë´‡ ğŸ’¬")
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        try:
            # RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
            context = ""
            if st.session_state.vectorstore is not None:
                docs = st.session_state.vectorstore.similarity_search(prompt, k=3)
                context = "\n\n".join([doc.page_content for doc in docs])
                
            # Claude API í˜¸ì¶œ
            client = Anthropic(api_key=st.session_state.anthropic_api_key)
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ë©”ì‹œì§€ ìƒì„±
            messages = [
                {"role": "system", "content": st.session_state.system_prompt},
                {"role": "user", "content": f"""Context: {context}\n\nQuestion: {prompt}
                Please provide an answer based on the given context. If the context doesn't contain relevant information,
                you can provide a general response."""}
            ]
            
            response = client.messages.create(
                model="claude-3-opus-20240229",
                max_tokens=1000,
                temperature=0.7,
                messages=messages
            )
            
            # ì‘ë‹µ í‘œì‹œ
            with st.chat_message("assistant"):
                st.markdown(response.content)
            st.session_state.messages.append({"role": "assistant", "content": response.content})
            
        except Exception as e:
            st.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ë©”ì¸ ì•± ë¡œì§
def main():
    # ì‚¬ì´ë“œë°”ì— ì„¤ì • ì´ˆê¸°í™” ë²„íŠ¼
    if st.sidebar.button("ì„¤ì • ì´ˆê¸°í™”"):
        st.session_state.initialized = False
        st.session_state.settings_confirmed = False
        st.session_state.messages = []
        st.rerun()
    
    # ì´ˆê¸° ì„¤ì • ë˜ëŠ” ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ
    if not st.session_state.settings_confirmed:
        initialize_settings()
    else:
        chat_interface()

if __name__ == "__main__":
    main()